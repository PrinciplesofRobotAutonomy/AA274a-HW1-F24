{"cells":[{"cell_type":"markdown","metadata":{"id":"WshFeYmnY8sT"},"source":["# HW1 AA274A Problem 3\n","\n","In this problem, you will write a trajectory optimization algorithm to generate a feasible trajectory subject to some constraints. Our setup includes the \"ego\" vehicle (meaning the agent we control), a static obstacle, and a goal position to be reached.\n","\n","In this setup, we will not make the assumption of differential flatness and instead solve the problem with a nonlinear optimizer!\n"]},{"cell_type":"markdown","metadata":{"id":"Z09yDOn0fSvM"},"source":["# Problem Setup\n","We will first consider the case in which we are trying to generate a trajectory for a Turtlebot that must avoid an object. The agent has an initial position, a goal position, and a big obstacle in the center of the initial path. Our agent therefore must generate a trajectory that is dynamically feasible, does not collide with the obstacle, and reaches the final goal pose."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8dsWwGaDcwdY"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.optimize import minimize, Bounds\n","import typing as T"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"jfWNEbKMhCio"},"outputs":[],"source":["from utils import simulate_car_dyn, maybe_makedirs\n","from P3_trajectory_tracking import TrajectoryTracker"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aXBY0tKZY-QT"},"outputs":[],"source":["# Initial conditions and parameters\n","EGO_START_POS, EGO_FINAL_GOAL_POS = (0.0,0.0), (5.0,5.0)\n","EGO_RADIUS, OBS_RADIUS = 0.1, 0.3\n","OBSTACLE_POS = (2.5, 2.5)"]},{"cell_type":"markdown","metadata":{"id":"Lb1lyHx8fwKB"},"source":["# Visualizing the Scene"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qsiPYMzchxf"},"outputs":[],"source":["def render_scene(traj=None, print_alpha=None):\n","  fig, ax = plt.subplots()\n","  ego_circle_start = plt.Circle(EGO_START_POS, radius=EGO_RADIUS, color='lime')\n","  ego_circle_end   = plt.Circle(EGO_FINAL_GOAL_POS, radius=EGO_RADIUS, color='red')\n","  obs_circle       = plt.Circle(OBSTACLE_POS, radius=OBS_RADIUS, color='blue')\n","  ax.add_patch(obs_circle)\n","  if traj is not None:\n","    for i in range(traj.shape[0]):\n","      x,y,theta = traj[i]\n","      ego_circle_current = plt.Circle((x, y), radius=EGO_RADIUS, color='cyan')\n","      ax.add_patch(ego_circle_current)\n","      ego_arrow_current = plt.arrow(x, y, dx=np.cos(theta)/2, dy=np.sin(theta)/2, head_width=0.1)\n","      ax.add_patch(ego_arrow_current)\n","  ax.add_patch(ego_circle_start)\n","  ax.add_patch(ego_circle_end)\n","  ax.set_xlim((-1.0, 6.0))\n","  ax.set_ylim((-1.0, 6.0))\n","  ax.set_aspect('equal')\n","  if print_alpha is not None:\n","    plt.title(\"Alpha: {:.2f}\".format(print_alpha))\n","  return plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1696018252736,"user":{"displayName":"Keiko Nagami","userId":"10093190229210908038"},"user_tz":420},"id":"sa-nhG64dMlw","outputId":"0c6b3ccf-bc22-4300-cd3a-121b6664a067"},"outputs":[],"source":["# VIZUALIZE THE INITIAL SCENE\n","# RED circle is the obstacle\n","# GREEN is ego start position\n","# BLUE is obstacle position\n","plt = render_scene()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"N2rPg41Ohu6E"},"source":["## Code Setup\n","\n","Here we will define some essential values for our problem (such as the initial state, final state, etc.). We have also provided two helper functions that may be useful for you!\n","\n","**TODO:** Fill in code for the initial and final state of the ego agent below. Some hints are provided in the code comments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pm850gRihuEZ"},"outputs":[],"source":["############################## Code starts here ##############################\n","# TODO: Define the initial and final state as numpy arrays for the ego agent here\n","# HINTS: Our state is a 3 dimensional vector [x, y, heading].\n","s_0 = None  # Initial state.\n","s_f = None  # Final state.\n","############################## Code ends here ##############################\n","\n","N = 50  # Number of time discretization nodes (0, 1, ... N).\n","s_dim = 3  # State dimension; 3 for (x, y, th).\n","u_dim = 2  # Control dimension; 2 for (V, om).\n","v_max = 0.5  # Maximum linear velocity.\n","om_max = 1.0  # Maximum angular velocity.\n","\n","def pack_decision_variables(t_f: float, s: np.ndarray, u: np.ndarray) -> np.ndarray:\n","    \"\"\"Packs decision variables (final time, states, controls) into a 1D vector.\n","\n","    Args:\n","        t_f: Final time, a scalar.\n","        s: States, an array of shape (N + 1, s_dim).\n","        u: Controls, an array of shape (N, u_dim).\n","\n","    Returns:\n","        An array `z` of shape (1 + (N + 1) * s_dim + N * u_dim,).\n","    \"\"\"\n","    return np.concatenate([[t_f], s.ravel(), u.ravel()])\n","\n","\n","def unpack_decision_variables(z: np.ndarray) -> T.Tuple[float, np.ndarray, np.ndarray]:\n","    \"\"\"Unpacks a 1D vector into decision variables (final time, states, controls).\n","\n","    Args:\n","        z: An array of shape (1 + (N + 1) * s_dim + N * u_dim,).\n","\n","    Returns:\n","        t_f: Final time, a scalar.\n","        s: States, an array of shape (N + 1, s_dim).\n","        u: Controls, an array of shape (N, u_dim).\n","    \"\"\"\n","    t_f = float(z[0])\n","    s = z[1:1 + (N + 1) * s_dim].reshape(N + 1, s_dim)\n","    u = z[-N * u_dim:].reshape(N, u_dim)\n","    return t_f, s, u"]},{"cell_type":"markdown","metadata":{"id":"Tnq6CNk7g2A2"},"source":["## Trajectory Optimization\n","\n","Next, we will define a function to set up and solve the trajectory optimization problem. Consider the following questions:\n","\n","\n","\n","1.   What is the cost for a given trajectory?\n","2.   What are the **constraints** that the trajectory must obey? Constraints here are *equality* constraints.\n","\n","We will use scipy.optimize.minimize to solve this nonlinear optimization problem. You can find some documentation for this function [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ku5f2oEudUyJ"},"outputs":[],"source":["def optimize_trajectory(\n","    time_weight: float = 1.0,\n","    verbose: bool = True\n","):\n","    \"\"\"Computes the optimal trajectory as a function of `time_weight`.\n","\n","    Args:\n","        time_weight: \\alpha in the HW writeup.\n","\n","    Returns:\n","        t_f_opt: Final time, a scalar.\n","        s_opt: States, an array of shape (N + 1, s_dim).\n","        u_opt: Controls, an array of shape (N, u_dim).\n","    \"\"\"\n","\n","    def cost(z):\n","        ############################## Code starts here ##############################\n","        # TODO: Define a cost function here\n","        # HINT: you may find `unpack_decision_variables` useful here. z is the packed 1D representation of t,s and u. Return the value of the cost.\n","\n","        ############################## Code ends here ##############################\n","\n","    # Initialize the trajectory with a straight line\n","    z_guess = pack_decision_variables(\n","        20, s_0 + np.linspace(0, 1, N + 1)[:, np.newaxis] * (s_f - s_0),\n","        np.ones(N * u_dim))\n","\n","    # Minimum and Maximum bounds on states and controls\n","    # This is because we would want to include safety limits\n","    # for omega (steering) and velocity (speed limit)\n","    bounds = Bounds(\n","        pack_decision_variables(\n","            0., -np.inf * np.ones((N + 1, s_dim)),\n","            np.array([0.01, -om_max]) * np.ones((N, u_dim))),\n","        pack_decision_variables(\n","            np.inf, np.inf * np.ones((N + 1, s_dim)),\n","            np.array([v_max, om_max]) * np.ones((N, u_dim)))\n","    )\n","\n","    # Define the equality constraints\n","    def eq_constraints(z):\n","        t_f, s, u = unpack_decision_variables(z)\n","        dt = t_f / N\n","        constraint_list = []\n","        for i in range(N):\n","            V, om = u[i]\n","            x, y, th = s[i]\n","            ############################## Code starts here ##############################\n","            # TODO: Append to `constraint_list` with dynanics constraints\n","\n","            ############################## Code ends here ##############################\n","\n","        ############################## Code starts here ##############################\n","        # TODO: Append to `constraint_list` with initial and final state constraints\n","\n","        ############################## Code ends here ##############################\n","        return np.concatenate(constraint_list)\n","\n","    # Define the inequality constraints\n","    def ineq_constraints(z):\n","      t_f, s, u = unpack_decision_variables(z)\n","      dt = t_f / N\n","      constraint_list = []\n","      for i in range(N):\n","          V, om = u[i]\n","          x, y, th = s[i]\n","          ############################## Code starts here ##############################\n","          # TODO: Append to `constraint_list` with collision avoidance constraint\n","\n","          ############################## Code ends here ################################\n","      return np.array(constraint_list)\n","\n","    result = minimize(cost,\n","                      z_guess,\n","                      bounds=bounds,\n","                      constraints=[{\n","                          'type': 'eq',\n","                          'fun': eq_constraints\n","                      },\n","                      {\n","                          'type': 'ineq',\n","                          'fun': ineq_constraints\n","                      }])\n","    if verbose:\n","        print(result)\n","\n","    return unpack_decision_variables(result.x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EfGNzPN8jHST"},"outputs":[],"source":["# Call the trajectory optimizer\n","t, s, u = optimize_trajectory()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WX-R-89YXVbK"},"outputs":[],"source":["# Plot optimized trajectory\n","plt = render_scene(s)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_JNEkklO1yTS"},"source":["Let's write a small wrapper function which gives us a plot of the trajectory for a given value of alpha"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ePmxqd0V16Gq"},"outputs":[],"source":["def show_traj_plan(alpha=1.0):\n","  t, s, u = optimize_trajectory(time_weight=alpha)\n","  plt = render_scene(s, print_alpha=alpha)\n","  plt.show()"]},{"cell_type":"markdown","metadata":{"id":"nvJ5yJ-V2IbY"},"source":["## Varying alpha\n","Let us now experiment with different values of alpha to see how the output changes. We have included three examples below, but feel free to experiment with other values as well!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zycxbTK72hRL"},"outputs":[],"source":["show_traj_plan(alpha=1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"De2z_OQB3SRr"},"outputs":[],"source":["show_traj_plan(alpha=20.0)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
